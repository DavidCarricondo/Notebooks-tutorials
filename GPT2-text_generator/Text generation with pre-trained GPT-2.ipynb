{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT GENERATOR WITH GPT-2 PRE-TRAINED MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://huggingface.co/blog/how-to-generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating text with beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: I enjoy walking with my cute dog, but I don't know if I'll ever be able to walk with him again.\n",
      "\n",
      "I'm not sure if it's because I'm afraid of him, or if he's scared of me. Either way, I love him so much, and I want him to be with me for the rest of my life. I can't wait to see what he has to offer.\n",
      "\n",
      "1: I enjoy walking with my cute dog, but I don't know if I'll ever be able to walk with him again.\n",
      "\n",
      "I'm not sure if it's because I'm afraid of him, or if he's scared of me. Either way, I love him so much, and I want him to be with me for the rest of my life.\n",
      "\n",
      "2: I enjoy walking with my cute dog, but I don't know if I'll ever be able to walk with him again.\n",
      "\n",
      "I'm not sure if it's because I'm afraid of him, or if he's scared of me. Either way, I love him so much, and I want him to be with me for the rest of my life. I can't wait to find out what happens next.\n",
      "\n",
      "3: I enjoy walking with my cute dog, but I don't know if I'll ever be able to walk with him again.\n",
      "\n",
      "I'm not sure if it's because I'm afraid of him, or if he's scared of me. Either way, I love him so much, and I want him to be with me for the rest of my life. I can't wait to see what happens next.\n",
      "\n",
      "4: I enjoy walking with my cute dog, but I don't know if I'll ever be able to walk with him again.\n",
      "\n",
      "I'm not sure if it's because I'm afraid of him, or if he's scared of me. Either way, I love him so much, and I want him to be with me for the rest of my life. I can't wait to see what he has to offer!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# encode context the generation is conditioned on\n",
    "input_ids = tokenizer.encode('I enjoy walking with my cute dog', return_tensors='tf')\n",
    "\n",
    "# generate text until the output length (which includes the context length) reaches 100 or early stops.\n",
    "beam_outputs = model.generate(input_ids, max_length=100,\n",
    "                               num_beams=10,\n",
    "                               no_repeat_ngram_size=2,\n",
    "                               num_return_sequences=5,\n",
    "                               early_stopping=True)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, beam_output in enumerate(beam_outputs):\n",
    "  print(\"{}: {}\\n\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating text with sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: I enjoy walking with my cute dog. I have a pet peeve. My son was born with a sprain. I love him. He has no sense of humor. I like to be alone with him. I like to have a good time with him. He is a nice, gentle, gentle person. He will like to be with me. He is the only person who is able to speak to me. He is a nice guy and he loves to talk to me. He has a\n",
      "\n",
      "1: I enjoy walking with my cute dog, and we always have her in our room for a reason. He is a wonderful person. He loves to be around us. He's a huge help to us all.\n",
      "\n",
      "He has been my best friend since high school. He has always been an amazing guy and he is a great friend to me. He has made me feel special, I feel so happy for him. He has always been my biggest support in the making. He is a great neighbor\n",
      "\n",
      "2: I enjoy walking with my cute dog and her little sister as they play in the backyard,\" he said.\n",
      "\n",
      "\"We have a very happy family and she is a very special dog. She will be a great companion to us,\" he added.\n",
      "\n",
      "3: I enjoy walking with my cute dog.\n",
      "\n",
      "4. I get to keep my dog for about two weeks, but my dog is a bit shy. Sometimes I would just sit down and give him a little bit of a walk to talk to him about something.\n",
      "\n",
      "5. I have to go to the vet and find out if my dog is sick. I am very sad to say that this is my first time in this situation and I know I am not the only one.\n",
      "\n",
      "\n",
      "\n",
      "4: I enjoy walking with my cute dog, and I love being able to tell him about the things I love about myself.\"\n",
      "\n",
      "Katherine also noted that she is a \"really good person.\"\n",
      "\n",
      "\"I don't think she's a bad person, but she's kind of a little too kind and I think that's something that I find very annoying,\" Katherine said.\n",
      "\n",
      "Katherine said she was a \"really good person\" when she met her fianc√©, who was a writer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# encode context the generation is conditioned on\n",
    "input_ids = tokenizer.encode('I enjoy walking with my cute dog', return_tensors='tf')\n",
    "\n",
    "# generate text until the output length (which includes the context length) reaches 100.\n",
    "sample_outputs = model.generate(input_ids, \n",
    "                                max_length=100,\n",
    "                                do_sample=True,\n",
    "                                top_k=50,\n",
    "                                top_p=0.95,\n",
    "                                temperature=0.7,\n",
    "                                num_return_sequences=5)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "  print(\"{}: {}\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit36b15ce491344c3aaf77177bbb6e80c7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
