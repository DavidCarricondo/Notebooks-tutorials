{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT GENERATOR WITH GPT-2 PRE-TRAINED MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://huggingface.co/blog/how-to-generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating text with beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: I enjoy walking with my cute dog, but I don't know if I'll ever be able to walk with him again.\n",
      "\n",
      "I'm not sure if it's because I'm afraid of him, or if he's scared of me. Either way, I love him so much, and I want him to be with me for the rest of my life. I can't wait to see what he has to offer.\n",
      "\n",
      "1: I enjoy walking with my cute dog, but I don't know if I'll ever be able to walk with him again.\n",
      "\n",
      "I'm not sure if it's because I'm afraid of him, or if he's scared of me. Either way, I love him so much, and I want him to be with me for the rest of my life.\n",
      "\n",
      "2: I enjoy walking with my cute dog, but I don't know if I'll ever be able to walk with him again.\n",
      "\n",
      "I'm not sure if it's because I'm afraid of him, or if he's scared of me. Either way, I love him so much, and I want him to be with me for the rest of my life. I can't wait to find out what happens next.\n",
      "\n",
      "3: I enjoy walking with my cute dog, but I don't know if I'll ever be able to walk with him again.\n",
      "\n",
      "I'm not sure if it's because I'm afraid of him, or if he's scared of me. Either way, I love him so much, and I want him to be with me for the rest of my life. I can't wait to see what happens next.\n",
      "\n",
      "4: I enjoy walking with my cute dog, but I don't know if I'll ever be able to walk with him again.\n",
      "\n",
      "I'm not sure if it's because I'm afraid of him, or if he's scared of me. Either way, I love him so much, and I want him to be with me for the rest of my life. I can't wait to see what he has to offer!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# encode context the generation is conditioned on\n",
    "input_ids = tokenizer.encode('I enjoy walking with my cute dog', return_tensors='tf')\n",
    "\n",
    "# generate text until the output length (which includes the context length) reaches 100 or early stops.\n",
    "beam_outputs = model.generate(input_ids, max_length=100,\n",
    "                               num_beams=10,\n",
    "                               no_repeat_ngram_size=2,\n",
    "                               num_return_sequences=5,\n",
    "                               early_stopping=True)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, beam_output in enumerate(beam_outputs):\n",
    "  print(\"{}: {}\\n\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating text with sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: During this short time, I developed a good practice using Python, SQL, machine learning and neural networks.  I worked with a couple of people on the project, including a very talented researcher named Thomas Hohmann.  I also had a couple of mentors working on my project, and a few mentors working on the project at least once.  These mentors included a few of my most experienced contributors, including a very talented programmer named John Dies at CERN.  I\n",
      "\n",
      "1: During this short time, I developed a good practice using Python, SQL, machine learning and neural networks.  This allowed me to get into the deep learning field quickly.  I also realized that I could use Python and SQL together.  My first programming language was Python, and I used it to build my first neural network (MNN) from scratch.  I started using Python and SQL together as a way to learn about the world.  I was able to get\n",
      "\n",
      "2: During this short time, I developed a good practice using Python, SQL, machine learning and neural networks.  At this point, I was a master of the language, but not a professional developer.  With that said, I was able to gain experience in many areas, including language design, development and code review.  This post is going to cover how to start with Python and SQL, as well as some of the other core concepts in Python.\n",
      "1. Language Design\n",
      "\n",
      "\n",
      "3: During this short time, I developed a good practice using Python, SQL, machine learning and neural networks.  This book is a complete overview of the techniques and concepts in neural networks, including the underlying neural network and a few of the other topics covered in this book.  In other words, this book is not a beginner's book, but is a step-by-step guide to becoming a master of neural networks.\n",
      "\n",
      "4: During this short time, I developed a good practice using Python, SQL, machine learning and neural networks.  I was able to achieve this result with very little effort, however, I have been able to maintain a good database of the data and I can now start writing a program to automatically create a new list of results.\n",
      "This is a very simple program, but it has some interesting features, which you will learn in this article.  It uses Python and has a few features that\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# encode context the generation is conditioned on\n",
    "input_ids = tokenizer.encode('During this short time, I developed a good practice using Python, SQL, machine learning and neural networks.', return_tensors='tf')\n",
    "\n",
    "# generate text until the output length (which includes the context length) reaches 100.\n",
    "sample_outputs = model.generate(input_ids, \n",
    "                                max_length=100,\n",
    "                                do_sample=True,\n",
    "                                top_k=50,\n",
    "                                top_p=0.95,\n",
    "                                temperature=0.7,\n",
    "                                num_return_sequences=5)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "  print(\"{}: {}\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit36b15ce491344c3aaf77177bbb6e80c7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
